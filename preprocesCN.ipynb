{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocesCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridaIndah/Proyek-Mandiri/blob/main/preprocesCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XG84OBYeWP8"
      },
      "source": [
        "Pre process conceptnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iC_7tvrdf1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0388740-bad5-4d60-f418-a5f2943c285e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLL07C3bekRv",
        "outputId": "7e694a41-7629-4c0c-a3f0-c478be408dee"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/Proyek Mandiri/data/assertions.zip' -d \"/content/drive/MyDrive/Proyek Mandiri/data\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Proyek Mandiri/data/assertions.zip\n",
            "  inflating: /content/drive/MyDrive/Proyek Mandiri/data/conceptnet-assertions-5.7.0.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbxFCuGWkUg6"
      },
      "source": [
        "Preprocess conceptnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dou8aJTCm-T8"
      },
      "source": [
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbY8J0fkTAs"
      },
      "source": [
        "import csv\n",
        "import argparse\n",
        "from ast import literal_eval\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8An1ErxnHCt"
      },
      "source": [
        "def get_ngrams(utter, n):\n",
        "        # utter: a list of tokens\n",
        "        # n: up to n-grams\n",
        "        total = []\n",
        "        for i in range(len(utter)):\n",
        "            for j in range(i, max(i-n, -1), -1):\n",
        "                total.append(\"_\".join(utter[j:i+1]))\n",
        "        return total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmESrEaynLIZ"
      },
      "source": [
        "# get all ngrams for a dataset\n",
        "def get_all_ngrams(examples, n):\n",
        "    all_ngrams = []\n",
        "    for ex in examples:\n",
        "        for utter, _,_,_ in ex:\n",
        "            all_ngrams.extend(get_ngrams(utter, n))\n",
        "    return set(all_ngrams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6shLndgJnosa"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def to_pickle(obj, fname):\n",
        "    with open(fname, \"wb\") as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_pickle(fname):\n",
        "    with open(fname, \"rb\") as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq7c3g62nOOa",
        "outputId": "0364c5f6-956d-4989-8ee2-b1883bdb3b04"
      },
      "source": [
        "print(\"Loading dataset...\")\n",
        "dataset='DD'\n",
        "train = load_pickle(\"/content/drive/MyDrive/Proyek Mandiri/data5/{0}/{1}.pkl\".format(dataset, \"train\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzzfqtngobyQ"
      },
      "source": [
        "val = load_pickle(\"/content/drive/MyDrive/Proyek Mandiri/data5/{0}/{1}.pkl\".format(dataset, \"val\"))\n",
        "test = load_pickle(\"/content/drive/MyDrive/Proyek Mandiri/data5/{0}/{1}.pkl\".format(dataset, \"test\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBcnZ0N_o-WT"
      },
      "source": [
        "n=1\n",
        "ngrams = get_all_ngrams(train+val+test, n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD13QHGxpCni"
      },
      "source": [
        "# get concepts for each ngram\n",
        "print(\"Loading conceptnet...\")\n",
        "csv_reader = csv.reader(open(\"/content/drive/MyDrive/Proyek Mandiri/data/conceptnet-assertions-5.7.0.csv\", \"r\"), delimiter=\"\\t\")\n",
        "concept_dict = defaultdict(set)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucoag-mopbGQ",
        "outputId": "3dd437b6-6a8a-4558-98d2-2c222c3acdae"
      },
      "source": [
        "for i, row in enumerate(csv_reader):\n",
        "        if i%1000000 == 0:\n",
        "            print(\"Processed {0} rows\".format(i))\n",
        "        \n",
        "        lang = row[2].split(\"/\")[2]\n",
        "        if lang == 'en':\n",
        "            c1 = row[2].split(\"/\")[3]\n",
        "            c2 = row[3].split(\"/\")[3]\n",
        "            weight = literal_eval(row[-1])[\"weight\"]\n",
        "            if c1 in ngrams:\n",
        "                concept_dict[c1].add((c2, weight))\n",
        "            if c2 in ngrams:\n",
        "                concept_dict[c2].add((c1, weight))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed 0 rows\n",
            "Processed 1000000 rows\n",
            "Processed 2000000 rows\n",
            "Processed 3000000 rows\n",
            "Processed 4000000 rows\n",
            "Processed 5000000 rows\n",
            "Processed 6000000 rows\n",
            "Processed 7000000 rows\n",
            "Processed 8000000 rows\n",
            "Processed 9000000 rows\n",
            "Processed 10000000 rows\n",
            "Processed 11000000 rows\n",
            "Processed 12000000 rows\n",
            "Processed 13000000 rows\n",
            "Processed 14000000 rows\n",
            "Processed 15000000 rows\n",
            "Processed 16000000 rows\n",
            "Processed 17000000 rows\n",
            "Processed 18000000 rows\n",
            "Processed 19000000 rows\n",
            "Processed 20000000 rows\n",
            "Processed 21000000 rows\n",
            "Processed 22000000 rows\n",
            "Processed 23000000 rows\n",
            "Processed 24000000 rows\n",
            "Processed 25000000 rows\n",
            "Processed 26000000 rows\n",
            "Processed 27000000 rows\n",
            "Processed 28000000 rows\n",
            "Processed 29000000 rows\n",
            "Processed 30000000 rows\n",
            "Processed 31000000 rows\n",
            "Processed 32000000 rows\n",
            "Processed 33000000 rows\n",
            "Processed 34000000 rows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tmy1L5grL4D",
        "outputId": "0f37685b-51e5-4e79-8f12-17848fd58761"
      },
      "source": [
        "print(\"Saving concepts...\")\n",
        "to_pickle(concept_dict, \"/content/drive/MyDrive/Proyek Mandiri/data/KB/{0}.pkl\".format(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving concepts...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH_ZvxUGcljo"
      },
      "source": [
        "preprocess NC VAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om6b7292ctN7"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7rvVIz8cvOP"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Proyek Mandiri/data/NRC-VAD-Lexicon.txt\", sep='\\t')\n",
        "\n",
        "NRC = {}\n",
        "for i, row in df.iterrows():\n",
        "        NRC[row[0]] = tuple(row[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG3arbBdh7YH",
        "outputId": "7c580da4-4793-4163-d05c-91c7577620c0"
      },
      "source": [
        "path_to_save = \"/content/drive/MyDrive/Proyek Mandiri/data/KB/NRC.pkl\"\n",
        "print(\"Saving data to {0}\".format(path_to_save))\n",
        "with open(path_to_save, \"wb\") as f:\n",
        "    pickle.dump(NRC, f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving data to /content/drive/MyDrive/Proyek Mandiri/data/KB/NRC.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}